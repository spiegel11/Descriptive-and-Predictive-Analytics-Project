{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "## Instructions\n",
    "\n",
    "Your HW submission should consist of **one pdf or HTML file** exported from the Jupyter Notebook containing the answers to all the\n",
    "questions included in the homework.\n",
    "\n",
    "You will use Jupyter Notebook exclusively for this homework. All the cells in this notebook is editable. You need to edit, insert `markdown` and `code` cells to complete the homework.\n",
    "\n",
    "> If you are running this notebook on MyBinder, be sure to download your notebook, otherwise all your progress will be lost. You will need to reupload your notebook to MyBinder next time to restore progress.\n",
    "\n",
    "> If you are running this notebook locally on your own machine, you can simply save the notebook.\n",
    "\n",
    "> AVOID writing all your codes in a single cell if there are multiple lines with meaningful outputs. Separate them and insert new cells as you see fit.\n",
    "\n",
    "# Part 1\n",
    "\n",
    "In this part, R is not required. If you are able to get the right answer with R, that is OK but will not lead to bonus points.\n",
    "\n",
    "## Q1\n",
    "\n",
    "(1.5 points) Consider the following dataset which reflects purchases from a store. A value of 1, means that a given customer bought the corresponding product; a value of 0 means that a given customer did not buy the corresponding product.\n",
    "\n",
    "Calculate the Jaccard distance and the Matching distance between each pair of data-points.\n",
    "\n",
    "| Customer | Deodorant | Soap | Napkins | Razor | Shaving Cream | Sponge |\n",
    "|----------|-----------|------|---------|-------|---------------|--------|\n",
    "| A        | 1         | 1    | 1       | 0     | 1             | 1      |\n",
    "| B        | 1         | 0    | 1       | 1     | 0             | 0      |\n",
    "| C        | 1         | 0    | 1       | 1     | 1             | 1      |\n",
    "\n",
    "1. (0.5) Which two customers are the most similar based on Jaccard distance? Show your calculations.\n",
    "\n",
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer here, remember to change cell type to markdown\n",
    "Jaccard distance:\n",
    "d(A,B)= 4/6 = 0.67\n",
    "d(A,C)= 2/6 = 0.33\n",
    "d(B,C)= 2/5 = 0.4\n",
    "According to Jaccard distance, A is most similar to C, because 0.33<0.4<0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (0.5) Which two customers are the most similar based on Matching distance? Show your calculations.\n",
    "\n",
    "\n",
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching distance:\n",
    "d(A,B)= 4/6 = 0.67\n",
    "d(A,C)= 2/6 = 0.33\n",
    "d(B,C)= 2/6 = 0.33\n",
    "According to the matching distance, pair A&C and pair B&C are most similar because 0.33=0.33<0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (0.5) The store is probably selling more products than the ones that appear in the dataset above.\n",
    "\n",
    "Keeping that in mind, which distance metric between the matching distance and the Jaccard distance is best suited in this case? You must justify your answer.\n",
    "\n",
    "\n",
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, it is more important to focus on what people buy rather than what they do \n",
    "not buy. The intuition between the Jaccard Distance is that we exclude matches where both \n",
    "are 0. N00 is not as important as N11 because customer cannot buy everything in \n",
    "supermarket. What they buy is more important than what they do not buy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Assume you run k-means clustering on the dataset below and identified 2 clusters (reported in the column `Cluster`).\n",
    "\n",
    "For this question, you can use a spreadsheet software (e.g. Excel or Numbers) to check your calculations. Nevertheless, you must report in your submission all your calculations and the intermediate steps and calculations used to answer the question must be clear; otherwise, you will lose points.\n",
    "\n",
    "You can round your results to have 4 decimals.\n",
    "\n",
    "|   | Exam1 | Exam2 | Exam3 | Cluster |\n",
    "|---|-------|-------|-------|---------|\n",
    "| K | 91    | 89    | 95    | 2       |\n",
    "| L | 88    | 86    | 80    | 2       |\n",
    "| M | 75    | 82    | 78    | 1       |\n",
    "| N | 77    | 85    | 77    | 1       |\n",
    "| O | 80    | 83    | 80    | 1       |\n",
    "\n",
    "1. (0.5) Normalize the dataset using min-max normalization\n",
    "\n",
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max(Exam1) = 91, Min(Exam1) = 75\n",
    "Max(Exam2) = 89, Min(Exam2) = 82\n",
    "Max(Exam3) = 95, Min(Exam3) = 77\n",
    "Min-max normalization: NewValue= (X- min)/(X- max)\n",
    "Normalization equation for Exam 1: = (Value-75)/(91-75)\n",
    "Normalization equation for Exam 2: = (Value-82)/(89-82)\n",
    "Normalization equation for Exam 3: = (Value-77)/(95-77)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (0.2 points) Compute the centroids for the two clusters and the centroid for the overall dataset\n",
    "\n",
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centroid of Cluster 1: (0.1458,0.1905,0.0741)\n",
    "Centroid of Cluster 2: ( 0.9063, 0.7857, 0.5833)\n",
    "Centroid of overall dataset: ( 0.45, 0.4286, 0.2778)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (1 point) Compute the WSS for each cluster and the Total WSS. How do we interpret the WSS?\n",
    "\n",
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WSS for Cluster 1:\n",
    "d(M, Center) = sqrt((0-0.1458)^2 + (0-0.1905)^2 + (0.0556-0.0741)^2) = 0.241\n",
    "d(N, Center) = 0.25; d(O, Center) = 0.197\n",
    "WSS for C1 = 0.25^2 + 0.241^2 + 0.197^2 = 0.159\n",
    "WSS for Cluster 2:\n",
    "d(K, Center) = 0.4778; d(L, Center) = 0.4778\n",
    "WSS for C2 = 0.4566\n",
    "WSS for the Total Dataset:\n",
    "WSS of C1 + WSS of C2 = 0.6158\n",
    "The total WSS is 0.6158. Lower WSS means more clusters are more cohesive within. For what \n",
    "we have for C1 0.159 and C2 0,4566, we can interpret C1 is more cohesive than C2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (0.8 points) Compute the BSS. How do we interpret the BSS?\n",
    "\n",
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centroid for cluster1: (0.1458, 0.1905, 0.0741)\n",
    "Centroid for cluster2: (0.9063, 0.7857, 0.5833)\n",
    "Centroid for the overall dataset: (0.45, 0.4286, 0.2778)\n",
    "d(C1, Center) = sqrt((0.1458-0.45)^2 + (0.1905-0.4286)^2 + (0.0741-0.2778)^2) * 3 = 0.5721\n",
    "d(C2, Center) = 0.8582\n",
    "BSS = 0.5721+0.8582 = 1.4303\n",
    "The total BSS is 1.4303. Higher BSS means clusters are more separated from each other. For \n",
    "what we have 1.4303 is a little bit high, which means low intre-similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Cluster Analysis in R\n",
    "\n",
    "(6 points total) For this part of the HW, you need to use the dataset `nba_2016.csv`, containing data about several players in the NBA for the year 2016. For each observation (player), the following information is available:\n",
    "\n",
    "- Tm: Team of the player\n",
    "- Player: Name of the player\n",
    "- Age: the age of the player\n",
    "- Yrs.Experience: years of experience of the player\n",
    "- G: Games played\n",
    "- MP: Minutes played\n",
    "- PER: Player Efficiency Rating; the higher the number, “the more efficient” the player. If you are curious and want to know more, look at this link: https://www.basketballreference.com/about/glossary.html\n",
    "- TS.: True shooting percentage\n",
    "- FTr: Free throws percentage\n",
    "- ORB.: Offensive rebounds (number)\n",
    "- DRB.: Defensive rebounds (number)\n",
    "- AST.: Assists (number)\n",
    "- STL.: Steals (number)\n",
    "- BLK.: Blocks (number)\n",
    "\n",
    "If you want further details, see: https://www.basketball-reference.com/about/glossary.html\n",
    "\n",
    "Follow the instructions below, and perform cluster analysis on the data using both hierarchical and kmeans clustering techniques. The objective is to cluster players based on their individual’s features and based on their performance’s measures.\n",
    "\n",
    "Remember, when it comes to clustering there is no “optimal” answer. Nevertheless, there are bad answers and good answers. To make your answer “good” you must justify any choice made through the process and comment on any output and graph you may produce.\n",
    "## 1 Preprocessing\n",
    "\n",
    "1. (0.2) Load the data and present a summary table for all the numerical variables. Describe in details the summary statistics for Age and PER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Tm                  Player         Age       Yrs.Experience \n",
       " ATL    :14   Adreian Payne   :  1   Min.   :19.0   Min.   : 1.00  \n",
       " BOS    :14   Al-Farouq Aminu :  1   1st Qu.:24.0   1st Qu.: 3.75  \n",
       " DEN    :14   Al Horford      :  1   Median :26.0   Median :14.00  \n",
       " GSW    :14   Allen Crabbe    :  1   Mean   :26.6   Mean   :11.64  \n",
       " HOU    :14   Amir Johnson    :  1   3rd Qu.:29.0   3rd Qu.:18.00  \n",
       " SAC    :14   Anderson Varejao:  1   Max.   :39.0   Max.   :22.00  \n",
       " (Other):64   (Other)         :142                                 \n",
       "       G               MP              PER              TS.        \n",
       " Min.   :1.000   Min.   :  2.00   Min.   :-22.80   Min.   :0.0000  \n",
       " 1st Qu.:4.000   1st Qu.: 50.25   1st Qu.:  8.20   1st Qu.:0.4490  \n",
       " Median :7.000   Median :127.50   Median : 13.90   Median :0.5355  \n",
       " Mean   :5.851   Mean   :128.80   Mean   : 13.61   Mean   :0.5146  \n",
       " 3rd Qu.:7.000   3rd Qu.:185.25   3rd Qu.: 18.73   3rd Qu.:0.6005  \n",
       " Max.   :9.000   Max.   :312.00   Max.   : 64.90   Max.   :1.2500  \n",
       "                                                                   \n",
       "      FTr              ORB.             DRB.            AST.      \n",
       " Min.   :0.0000   Min.   : 0.000   Min.   : 0.00   Min.   : 0.00  \n",
       " 1st Qu.:0.1087   1st Qu.: 1.300   1st Qu.: 9.10   1st Qu.: 5.60  \n",
       " Median :0.2500   Median : 3.950   Median :14.30   Median :11.25  \n",
       " Mean   :0.2774   Mean   : 5.641   Mean   :14.96   Mean   :13.59  \n",
       " 3rd Qu.:0.3752   3rd Qu.: 8.325   3rd Qu.:19.98   3rd Qu.:17.12  \n",
       " Max.   :1.5000   Max.   :57.800   Max.   :37.10   Max.   :57.10  \n",
       "                                                                  \n",
       "      STL.             BLK.       \n",
       " Min.   : 0.000   Min.   : 0.000  \n",
       " 1st Qu.: 0.600   1st Qu.: 0.000  \n",
       " Median : 1.400   Median : 0.950  \n",
       " Mean   : 1.678   Mean   : 1.769  \n",
       " 3rd Qu.: 2.225   3rd Qu.: 2.225  \n",
       " Max.   :10.800   Max.   :15.300  \n",
       "                                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your R code starts here\n",
    "#library(stats)\n",
    "#library(factoextra)\n",
    "data_nba <- read.csv(\"nba_2016.csv\")\n",
    "summary(data_nba)\n",
    "#Average age of NBA players is 26.6, the age of the oldest player is 39, the age of the youngest player is 19.\n",
    "#Player efficiency Rating: the mean of PER is 13.61, the highest PER is 64.90, the lowest PER is -22.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (0.4) Plot the relationship between Age and PER in a scatterplot, using ggplot. Have the color of the points on the plot change based on Yrs.Experience. Your plot should have a proper title, axis labels and the Y axis should start from 0; change the other axis limits as you believe appropriate. Describe the insights you derive from the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in +ggtitle(\"The Relationship between Age and PER of NBA Players\"): 一进列运算符的参数不对\n",
     "output_type": "error",
     "traceback": [
      "Error in +ggtitle(\"The Relationship between Age and PER of NBA Players\"): 一进列运算符的参数不对\nTraceback:\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): 无法启动png()装置\n",
     "output_type": "error",
     "traceback": [
      "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): 无法启动png()装置\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "library(\"ggplot2\")\n",
    "ggplot(data = data_nba, aes(x=PER, y=Age, color=Yrs.Experience)) + geom_point(size=3) + ylim(0,40) \n",
    "+ ggtitle(\"The Relationship between Age and PER of NBA Players\") + labs(x=\"Age\",y=\"Player efficiency rating\")\n",
    "#Insights: Based on the graph, experiences may have a positive influence on the PER. And the \n",
    "#age distribute is intensive around ±25. Younger could have a higher PER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (0.3) Assess which attributes/variables you should include in your cluster analysis and whether you need to exclude some. Justify your choices. (For this question, you do not need to code but you must explain your choices). Remember that the objective is to cluster players based on their individual’s features and based on their performance’s measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no code necessary, change this cell to markdown\n",
    "In this case, the column Player contains the name of each player; it is not an attribute we will \n",
    "use for clustering. So we will exclude it.The attribute Tm is also categorical. Since the variable \n",
    "Tm already “groups” players into teams, we can argue that is would not add much to cluster \n",
    "analysis, therefore we can decide to exclude it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (0.3) Assess whether you need to normalize the data. If yes, explain why and create the function in R to implement min-max normalization and perform the normalization on the appropriate attributes (you may want to create a copy of your dataset). Simply write down the code below. If you do not think normalization is necessary, explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in View(data_nba): 'View()' not yet supported in the Jupyter R kernel\n",
     "output_type": "error",
     "traceback": [
      "Error in View(data_nba): 'View()' not yet supported in the Jupyter R kernel\nTraceback:\n",
      "1. View(data_nba)",
      "2. stop(sQuote(\"View()\"), \" not yet supported in the Jupyter R kernel\")"
     ]
    }
   ],
   "source": [
    "#Normalization is necessary. For different columns, they have different ranges, which will \n",
    "#distort the distance calculation. We need to transform the attributes so they all have the \n",
    "#value from a common range.\n",
    "View(data_nba)\n",
    "normalize <- function(x) { \n",
    "  return ((x - min(x)) / (max(x) - min(x)))}\n",
    "norm_nba <- data_nba\n",
    "norm_nba <- apply(norm_nba, MARGIN = 2, FUN = normalize)\n",
    "View(norm_nba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Hierarchical Clustering\n",
    "\n",
    "1. (0.25) Generate a distance matrix using Euclidean distance and using the attributes you chose to include in your cluster analysis. Report the code and output the first 5 columns/rows of the distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_norm = dist(norm_nba,method=\"euclidean\")\n",
    "View(as.matrix(distance_matrix_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (0.25) Run hierarchical clustering using the distance matrix produced above and using the Ward method. Only report the code for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_norm = dist(norm_nba,method=\"euclidean\")\n",
    "View(as.matrix(distance_matrix_norm))\n",
    "h_1 = hclust(distance_matrix_norm,method=\"ward.D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (0.25) Plot the dendrogram, make sure to adjust the size of the labels to `0.4` and `hang = -1`. (you can leave the numbers as labels for this dendrogram). Attach the output to the answer. It is ok if the labels look small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(h_1,hang=-1,cex=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (0.25) Use the `rect.hclust()` function to draw on the dendrogram the best 4-clusters solution. The borders of each cluster should have a different color. You may need to copy the `plot()` code from last question as the first line of code before `rect.hclust()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect.hclust(h_1, k=4, border=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (0.25) Cut the dendrogram into the 4 clusters and report the size of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in nrow(tree$merge): 找不到对象'h1'\n",
     "output_type": "error",
     "traceback": [
      "Error in nrow(tree$merge): 找不到对象'h1'\nTraceback:\n",
      "1. cutree(h1, k = 4)",
      "2. nrow(tree$merge)"
     ]
    }
   ],
   "source": [
    "hcluster_4 <- cutree(h1,k=4)\n",
    "table(hcluster_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (0.5) Add a column to the original dataset with the cluster’s number to which each observation belongs to; use the function `ddply()` to get the means, for each cluster, for the following attributes: PER, Yrs.Experience, AST. Make sure to report the summary table, along with the code. Comment on the differences and/or similarities among the clusters, based on the means for those three attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_2016$hcluster_4 <- hcluster_4\n",
    "ddply(nba_2016, .(hcluster_4), summarize, PER = mean(PER),Experience = mean(Yrs.Experience),AST=mean(AST.))\n",
    "#For the mean of the three attributes we calculated, cluster 2 and 3 are little bit similar to each \n",
    "#other with relatively large in all three attributes. Cluster 1 and 4 are more similar based on \n",
    "#both short on experience and the number of PER and AST are close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (0.25) Create a table of clusters’ distribution by Teams. Report the table and comment about any interesting pattern you may notice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(nba_2016$Tm,nba_2016$hcluster_4)\n",
    "#Comments: There is no clear indicates about which team closer to which clusters, data is equally distributed.\n",
    "#BOS and MIN don't have any data points in cluster 2, and POR had no datapoints in cluster 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (0.5) Use again the `ddply()` to get the means, by Teams, for the attributes: PER, Yrs.Experience and AST. Identify, for each of the three attributes (PER, Yrs.Experience, AST), the two teams with the lowest and highest mean, and then look back at the clusters’ distribution for those two teams (from Q7). Do you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddply(nba_2016, .(hcluster_4), summarize, PER = mean(PER),Experience = mean(Yrs.Experience),AST=mean(AST.))\n",
    "#PER(player efficiency rating): Lowest: POR: 10.28462 Highest: GSW: 17.58571 \n",
    "#POR: mostly distribute in cluster 2, and no datapoint in cluster 3\n",
    "#GSW: mostly distribute in cluster 2, only 1 data point in cluster 1\n",
    "#Yrs.Experience(years of experience): Lowest: MIN: 7.538462 Highest: SAC: 15.285714\n",
    "#MIN: mostly distribute in cluster 4, and no datapoint in cluster 2\n",
    "#SAC: mostly distribute in cluster 2, only 1 data point in cluster 1\n",
    "#AST(assists): Lowest: POR: 9.138462 Highest: GSW: 17.392857\n",
    "#POR: mostly distribute in cluster 2, and no datapoint in cluster 3\n",
    "#GSW: mostly distribute in cluster 2, only 1 data point in cluster 1\n",
    "#There may be a positive relationship between player efficiency rating and assists, for the \n",
    "#cluster analysis, POR is the lowest in both PER and AST and GSW is the highest. We can also \n",
    "#interpret POR and GSW have better performance than other teams based on PER and AST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.3 points) K-Means Clustering\n",
    "\n",
    "1. (0.3) Run k-means clustering with 5 clusters and `nstart = 10`. Make sure to use the attributes you used for hierarchical clustering and decide whether to use the normalized data. You only need to show your code for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "k1 = kmeans(norm_nba,centers=5,nstart=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (0.4) Use the `str()` function to get a summary of the k-means clustering solutions. Comment on the elements' withiness, betweeness and size capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(k1)\n",
    "#Withinss: WSS for the five cluster: 9.68, 6.34, 10.33, 10.34, 3.98\n",
    "#Betweenss: sum of BSS of all clusters: 34.5\n",
    "#Size: how many points in each cluster: 17, 39, 44, 27, 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (0.5) Plot the clusters using the `fviz_cluster` function, and using as dimensions Yrs.Experience and PER. Describe the insights you derive from the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friz_cluster(k1, geom=\"point\", data = norm_nba, choose.vars = c(\"Yrs.Experience\",\"PER\")) \n",
    "+ ggtitle(\"Clusters\")\n",
    "#We choose two attributes: Yrs.Experience and PER and plot the clusters as function of these \n",
    "#two dimensions. While we cannot directly interpret the numbers on the axis, we can \n",
    "#interpret the “direction”. From the plot, it seems like teams in yellow and green \n",
    "#clusters tend to have relatively higher values of Yrs.Experience and mid-level of PER. On the \n",
    "#other hand, there are teams in the blue cluster that seems to have relatively higher PER and \n",
    "#lower Yrs.Experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (0.5) Find what you think is the most appropriate number of clusters by computing the WSS (only) and plotting the Elbow plot. Use a loop to run k-means for 10 times, and set `nstart = 10`. When you plot the result, make sure the y-axis starts from 0. Comment on the plot obtained and explain what you think it may be an appropriate number of clusters. You need to motivate your choice. If you are undecided between two/three options, say so and explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSS_curve <- c()\n",
    "for (n in 1:10) {k = kmeans(norm_nba),centers = n, nstart=10)\n",
    "                wss <- k$tot.withinss\n",
    "                WSS_curve[n] <- wss}\n",
    "plot(1:10,WSS_curve,type=\"b\",col=\"red\",ylab=\"WSS\",xlab=\"K\",ylim=c(0,80))\n",
    "#I think K=2 may be the appropriate numbers of clusters. We pick the number of clusters that \n",
    "#corresponds to the “Elbow point”, point where the curve bends. When k=2, there are \n",
    "#dramatically decrease of WSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (0.3) Compute the WSS (only) and plot the Elbow plot again, this time using a loop that runs kmeans for 40 times, and set `nstart = 10`. Make sure to change the axis of the plot accordingly. Does your opinion about the appropriate number of clusters change, compared to the answer gave in the previous point? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n in 1:40) {k = kmeans(norm_nba),centers = n, nstart=10)\n",
    "                wss <- k$tot.withinss\n",
    "                WSS_curve[n] <- wss}\n",
    "plot(1:40,WSS_curve,type=\"b\",col=\"red\",ylab=\"WSS\",xlab=\"K\",ylim=c(0,80))\n",
    "#After running K-means for 40 times, I think from K=2 to K=7 may be the appropriate numbers of \n",
    "#clusters. We pick the number of clusters that corresponds to the “Elbow point”, point where \n",
    "#the curve bends. When k=2 to7, there are dramatically decrease of WSS. \n",
    "#My opinion about the appropriate number of clusters changed, for 40-times k-means \n",
    "#calculation, it is hard to decide the “Elbow point”. The curve is smooth, especially for large K, \n",
    "#the WSS not change a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (0.3) Finally, compute both WSS, BSS and plot both. Use a loop that runs the k-means 40 times and set nstart = 10. Make sure your y-axis starts from 0 and the x-axis captures all the 40 runs. Does your opinion about the appropriate number of clusters change, compared to the previous two points? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSS_curve <- c()\n",
    "BSS_curve <- c()\n",
    "for (n in 1:40) {k = kmeans(norm_nba),centers = n, nstart=10)\n",
    "                wss <- k$tot.withinss\n",
    "                bss <- k$betweenss\n",
    "                WSS_curve[n] <- wss\n",
    "                BSS_curve[n] <- bss}\n",
    "plot(1:40,WSS_curve,type=\"b\",col=\"red\",ylab=\"WSS and BSS\",xlab=\"K\",ylim=c(0,80))\n",
    "lines(1:40, BSS_curve, type=\"o\",col=\"blue\")\n",
    "#My opinion about the appropriate number of clusters do not change compared to the \n",
    "#previous two points. From the graph we generate, the WSS and BSS are around symmetry in \n",
    "#shape. For k=2 WSS and BSS are both change a lot.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
